{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#54B1FF\">Preprocessing:</span> &nbsp; <span style=\"color:#1B3EA9\"><b>Normalization</b></span>\n",
    "\n",
    "<br>\n",
    "\n",
    "**Normalization** is the process of scaling vectors so that they have a magnitude of one.  This is often done in a variety of mathematics problems. For example: in what direction does vector $\\boldsymbol{r}$ point? The answer to this question is a unit vector;  **normalization** computes unit vectors.\n",
    "\n",
    "This unit vector transformation is useful when you are more interested in **direction** than in **magnitude**. For example, if you are developing a machine learning algorithm whose goal is to predict the direction of travel of a walking person (based on a video stream, for example), the calculation result (i.e., the target value) will be a unit vector. The input data (i.e., the features) might also include unit vectors, for example: the direction of travel in previous frames, each of which is a unit vector.\n",
    "\n",
    "Unit feature vectors can easily be calculated in **sklearn** using the `preprocessing.normalize` function.\n",
    "\n",
    "Let's first import the packages we'll need for this notebook. We'll then consider some normalization examples.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n",
    "## Normalization basics\n",
    "\n",
    "The `preprocessing.normalize` function will transform a set of feature vectors into unit feature vectors:\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 104.88135039  571.51893664 1060.27633761]\n",
      " [ 104.4883183   542.36547993 1064.58941131]\n",
      " [  93.75872113  589.17730008 1096.36627605]\n",
      " [  88.34415188  579.17250381 1052.88949198]\n",
      " [ 106.80445611  592.55966383 1007.10360582]\n",
      " [  58.71292997  502.02183974 1083.26198455]\n",
      " [ 127.81567509  587.00121482 1097.86183422]\n",
      " [ 129.91585642  546.14793623 1078.05291763]]\n",
      "\n",
      "[[0.08674637 0.47269792 0.87694455]\n",
      " [0.08712114 0.45221802 0.88764225]\n",
      " [0.07511668 0.47203119 0.8783758 ]\n",
      " [0.07331978 0.48067472 0.87382837]\n",
      " [0.09102386 0.50500764 0.85830178]\n",
      " [0.0491166  0.41996895 0.90620839]\n",
      " [0.10213143 0.46904477 0.87724921]\n",
      " [0.10688577 0.44933272 0.88694732]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "x    = [50, 500, 1000] + 100 * np.random.rand(8, 3)\n",
    "xn   = preprocessing.normalize(x)\n",
    "\n",
    "print( x )\n",
    "print()\n",
    "print( xn )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "The feature vectors' magniutdes can be checked using the `np.linalg.norm` function like this:\n",
    "\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print( np.linalg.norm(xn, axis=1) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "Alternatively, you can manually calculate the vector magnitude ( $|x| = \\sqrt{x_0^2 + x_1^2 + x_2^2}$ ) like this:\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m = np.sqrt(   xn[:,0]**2 + xn[:,1]**2 + xn[:,2]**2  )\n",
    "\n",
    "print( m )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "___\n",
    "\n",
    "## Applying normalization to training and test sets\n",
    "\n",
    "⚠️ Unlike scaling, for which scaling parameters are calculated for the **training set**, and can optionally be applied to the **test set**, normalization is conducted on **individual feature vectors**, so normalization results do not depend on training.\n",
    "\n",
    "For example, we might be tempted to train a `Normalizer` on a training set like this:\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "x_train    = np.random.rand(10, 2)\n",
    "x_test     = 10 * np.random.rand(3, 2)\n",
    "\n",
    "\n",
    "\n",
    "normalizer = preprocessing.Normalizer()\n",
    "normalizer.fit(x_train)   # this line actually does not fit data;  see below\n",
    "\n",
    "x_train_n  = normalizer.transform( x_train )\n",
    "x_test_n   = normalizer.transform( x_test )\n",
    "\n",
    "print( np.linalg.norm(x_test_n, axis=1) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "However, note that the `Normalizer` actually does not fit data. This can be seen when the `fit` method is bypassed:\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "normalizer = preprocessing.Normalizer()\n",
    "x_train_n  = normalizer.transform( x_train )\n",
    "x_test_n   = normalizer.transform( x_test )\n",
    "\n",
    "print( np.linalg.norm(x_test_n, axis=1) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "For many processing routines, bypassing the `fit` method like this will result in an error.\n",
    "\n",
    "<br>\n",
    "\n",
    "Why does `Normalizer` have a `fit` method if `fit` does nothing?\n",
    "\n",
    "<br>\n",
    "\n",
    "The answer to this question is somewhat complex, and requires basic knowledge of data processing [pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline). A pipeline consists of a collection of data processing routines that are usually conducted in a sequential order. Since most processing routines use the `fit` method (and will not work until `fit` is called), all processing routines in **sklearn** implement a `fit` method, regardless of whether `fit` actually does anything. This makes it easy to substitute and/or sequentially apply processing routines. For example:\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32.46150544 29.19906584]\n",
      " [14.34386741 28.45888677]\n",
      " [ 2.31989891 22.87227202]]\n",
      "\n",
      "[[0.74347962 0.66875859]\n",
      " [0.45008362 0.89298641]\n",
      " [0.1009107  0.99489549]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "x_train    = np.random.rand(10, 2)\n",
    "x_test     = 10 * np.random.rand(3, 2)\n",
    "\n",
    "routine0   = preprocessing.StandardScaler()\n",
    "routine1   = preprocessing.Normalizer()\n",
    "\n",
    "# apply routines sequentially:\n",
    "for r in [routine0, routine1]:\n",
    "    r.fit( x_train )  # if Normalizer did not have a \"fit\" method, this command would raise an error\n",
    "    x_test = r.transform( x_test )\n",
    "    print(x_test)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "If the `Normalizer` routine did **not** have a `fit` method, this type of sequential processing would be difficult.\n",
    "\n",
    "Refer to [sklearn's Pipeline documentation](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline) for more details regarding sequential data processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
