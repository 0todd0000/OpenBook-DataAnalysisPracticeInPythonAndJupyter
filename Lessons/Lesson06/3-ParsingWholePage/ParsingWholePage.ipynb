{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#54B1FF\">Exploring Data:</span> &nbsp; <span style=\"color:#1B3EA9\"><b>Parsing A Whole Page</b></span>\n",
    "\n",
    "<br>\n",
    "\n",
    "Just when you think you've understood the structure of a data file, you will very frequently encounter formatting problems, where entries don't follow the format you expect.\n",
    "\n",
    "The **page1.html** file is no exception. In the screenshot below you will notice that the \"Python Projects\" item (third from the top in this screenshot) does not contain the \"ページ\" word that we used to parse the page count in the previous notebook. Not only this, there is no page count at all!\n",
    "\n",
    "<br>\n",
    "<img src=\"img/ss6.png\" alt=\"screenshot\" width=700 />\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "How can we deal with this problem?\n",
    "\n",
    "One way is to ignore the entry if there is no \"ページ\" word found.  We'll get to this strategy below.\n",
    "\n",
    "First let's discuss a general strategy for parsing the whole page.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a name=\"parse-page\"></a>\n",
    "## General strategy\n",
    "[Back to Table of Contents](#toc)\n",
    "<br>\n",
    "\n",
    "A good general parsing strategy is to create a separate function for each part of the parsing process.\n",
    "\n",
    "Let's first import the modules we'll need for this notebook, then let's specify `dirData` as the directory in which the HTML data files are saved.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lxml.html\n",
    "\n",
    "dir0       = os.path.abspath('')              # directory in which this notebook is saved\n",
    "dirLesson  = os.path.dirname( dir0 )          # Lesson directory\n",
    "dirData    = os.path.join(dirLesson, 'Data')  # Data directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Let's next create functions to parse titles, prices and page counts, test them on the first book.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Django: Django , Web framework for Python\n",
      "1075\n",
      " 111\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def parse_name_node(node):\n",
    "    return node.text\n",
    "\n",
    "def parse_price_node(node):\n",
    "    s = node.text\n",
    "    x = s[1:].replace(',', '')\n",
    "    return int( x )\n",
    "\n",
    "def parse_page_count_node(node):\n",
    "    s = node.text\n",
    "    x = s.split(':')[1].split(',')[0]\n",
    "    return x\n",
    "\n",
    "\n",
    "fnameHTML   = os.path.join(dirData, 'page1.html')\n",
    "tree        = lxml.html.parse(fnameHTML)\n",
    "body        = tree.find('body') \n",
    "box         = body.find_class('itemCatBox')[0]\n",
    "name_nodes  = box.find_class('name')\n",
    "price_nodes = box.find_class('itemCatPrice')\n",
    "page_nodes  = box.find_class('itemCatsetsumei')\n",
    "\n",
    "\n",
    "name        = parse_name_node( name_nodes[0] )\n",
    "price       = parse_price_node( price_nodes[0] )\n",
    "pages       = parse_page_count_node( page_nodes[0] )\n",
    "\n",
    "\n",
    "print(name)\n",
    "print(price)\n",
    "print(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Great!\n",
    "\n",
    "It should now be relatively easy to parse the entire page, **but only** if all entries are formatted in the same way!!\n",
    "\n",
    "We know ahead of time that one of the pages will give us a problem, because it doesn't contain contain a page count.  Let's check which entry this is as follows:\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ページ: 111, ペーパーバック, Independently published\n",
      "1 ページ: 237, ペーパーバック, Independently published\n",
      "2 ページ: 205, ペーパーバック, Independently published\n",
      "3 ページ: 187, ペーパーバック, Independently published\n",
      "4 ページ: 110, ペーパーバック, Independently published\n",
      "5 ページ: 245, ペーパーバック, CreateSpace Independent Publishing Platform\n",
      "6 ページ: 224, ペーパーバック, Independently published\n",
      "7 ページ: 264, ペーパーバック, Lulu.com\n",
      "8 ページ: 104, ペーパーバック, Independently published\n",
      "9 ページ: 408, ペーパーバック, Independently published\n",
      "10 ページ: 220, ペーパーバック, Independently published\n",
      "11 ページ: 53, ペーパーバック, Independently published\n",
      "12 ページ: 162, ペーパーバック, Independently published\n",
      "13 ページ: 340, ペーパーバック, Packt Publishing\n",
      "14 ページ: 262, エディション: 1, ペーパーバック, Pragmatic Bookshelf\n",
      "15 Python ProjectsA guide to completing Python projects for those ready to take their skills to the next level  Python P...\n",
      "16 ページ: 706, エディション: 3, ペーパーバック, O'Reilly Media\n",
      "17 ページ: 215, エディション: 1st ed. 2018, ハードカバー, Springer\n",
      "18 ページ: 110, ペーパーバック, Independently published\n",
      "19 ページ: 107, ペーパーバック, Independently published\n",
      "20 ページ: 648, エディション: 2, ペーパーバック, Addison-Wesley Professional\n",
      "21 ページ: 248, ペーパーバック, Independently published\n",
      "22 ページ: 240, エディション: 1, ペーパーバック, Addison-Wesley Professional\n",
      "23 ページ: 378, エディション: 2nd Revised, ペーパーバック, Packt Publishing\n",
      "24 ページ: 386, ペーパーバック, Packt Publishing\n",
      "25 ページ: 39, ペーパーバック, Independently published\n",
      "26 ページ: 358, エディション: Second, ペーパーバック, Esri Press\n",
      "27 ページ: 216, ペーパーバック, Independently published\n",
      "28 ページ: 225, ペーパーバック, Independently published\n",
      "29 ページ: 334, ペーパーバック, Packt Publishing\n",
      "30 ページ: 244, ペーパーバック, Packt Publishing\n",
      "31 ページ: 330, ペーパーバック, Packt Publishing\n",
      "32 ページ: 156, ペーパーバック, Independently published\n",
      "33 ページ: 320, エディション: 1, ペーパーバック, Addison-Wesley Professional\n",
      "34 ページ: 110, ペーパーバック, Independently published\n",
      "35 ページ: 252, ペーパーバック, Packt Publishing\n",
      "36 ページ: 496, エディション: 2, ペーパーバック, For Dummies\n",
      "37 ページ: 128, ペーパーバック, Independently published\n",
      "38 ページ: 286, ペーパーバック, Packt Publishing\n",
      "39 ページ: 372, ペーパーバック, Packt Publishing\n"
     ]
    }
   ],
   "source": [
    "for i,node in enumerate( page_nodes ):\n",
    "    print( i, node.text )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "We can see that the 15th entry contains text that does not contain an integer page count. Let's deal with this problem by deciding what to do if the entry does not contain the word \"ページ\". Since we require an integer page count for all entries, let's set the page count for this entry to be `-1`. Setting the page count to `-1` when it is unknown will make it easier later to process all entries, irrespective of their page counts.\n",
    "\n",
    "This can be done in Python using an `if... else` command as demonstrated below.　Refer to the [control flow tools](https://docs.python.org/3/tutorial/controlflow.html) Python documentation, or [this tutorial in Japanese](https://www.javadrive.jp/python/if/index1.html) for details about `if... else` statements.\n",
    "\n",
    "First let's retrieve the problem node:\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python ProjectsA guide to completing Python projects for those ready to take their skills to the next level  Python P...\n"
     ]
    }
   ],
   "source": [
    "node = page_nodes[15]\n",
    "print(node.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "If we were to try to run the command `x = parse_page_count_node(node)` an error would be generated because this problem node does not follow the expeceted pattern. So let's adjust this function to deal with the problem node:\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "def parse_page_count_node(node):\n",
    "    s = node.text\n",
    "    if 'ページ' in s:\n",
    "        x = s.split(':')[1].split(',')[0]\n",
    "    else:\n",
    "        x = -1  # assign a value of -1 if \"ページ\" is not in the text field\n",
    "    return int( x )\n",
    "\n",
    "\n",
    "n = parse_page_count_node( node )\n",
    "\n",
    "print( n )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Great! Let's next confirm whether we can parse all page numbers using this new function.\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111, 237, 205, 187, 110, 245, 224, 264, 104, 408, 220, 53, 162, 340, 262, -1, 706, 215, 110, 107, 648, 248, 240, 378, 386, 39, 358, 216, 225, 334, 244, 330, 156, 320, 110, 252, 496, 128, 286, 372]\n"
     ]
    }
   ],
   "source": [
    "pages = []\n",
    "for node in page_nodes:\n",
    "    n = parse_page_count_node( node )\n",
    "    pages.append( n )\n",
    "\n",
    "print(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Excellent!  We have parsed all entries, and have returned a value of -1 for the problem entry.\n",
    "\n",
    "Note that the cell above can be written more compactly using a [list comprehension](https://www.pythonforbeginners.com/basics/list-comprehensions-in-python) statement, like this:\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111, 237, 205, 187, 110, 245, 224, 264, 104, 408, 220, 53, 162, 340, 262, -1, 706, 215, 110, 107, 648, 248, 240, 378, 386, 39, 358, 216, 225, 334, 244, 330, 156, 320, 110, 252, 496, 128, 286, 372]\n"
     ]
    }
   ],
   "source": [
    "pages = [parse_page_count_node( node )  for node in page_nodes]\n",
    "print(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "OK, we're now ready to parse the whole page, saving the title, page count and price for each entry:\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Django: Django , Web framework for Python', 'PYTHON PROGRAMMING ADVANCED: The Guide for Data Analysis and Data Science. Discover Machin...', \"Python Data Analytics: The Beginner's Real World Crash Course\", 'Programacion Con Python: Guia Completa para Principiantes   Aprende sobre Los Reinos De La...', 'Snake Reptile Week Planner Weekly Organizer Calendar 2020 / 2021 - Green Tree Python: Cute...', 'Python for Everybody: Exploring Data in Python 3', 'Python language for your growing children and for beginners', '101 Extra Python Challenges with Solutions / Code Listings', 'CIE IGCSE COMPUTER SCIENCE 9-1 SYLLABUS 2020-2021: PAPER 2 SPECIFICATION BOOK WITH FULL PY...', 'Computer Programming And Cyber Security for Beginners: This Book Includes: Python Machine ...', 'Python GUI: For Signal and Image Processing', 'Machine Learning with Scikit-Learn and TensorFlow: Deep Learning with Python (Random Fores...', 'Python Machine Learning: How to learn Machine Learning with Python. The Complete Guide to ...', 'Python Robotics Projects: Build smart and collaborative robots using Python', 'Complex Network Analysis in Python: Recognize - Construct - Visualize - Analyze - Interpre...', 'Python Projects【楽天海外直送】【英語の本】【洋書】', 'Python Cookbook: Recipes for Mastering Python 3', 'Simulating Nonlinear Circuits with Python Power Electronics: An Open-Source Simulator, Bas...', 'Snake Reptile Week Planner Weekly Organizer Calendar 2020 / 2021 - Golden Python: Cute Wil...', 'Always Be Yourself Unless You Can Be A Python Then Be A Python: Bucket List Journal', \"Programming in Python 3: A Complete Introduction to the Python Language (Developer's Libra...\", 'Python Crash Course: Strategy guide for beginners with examples and practical exercises (P...', \"Learn More Python 3 the Hard Way: The Next Step for New Python Programmers (Zed Shaw's Har...\", 'Python Machine Learning Blueprints: Put your machine learning concepts to the test by deve...', 'Hands-On Unsupervised Learning with Python: Implement machine learning and deep learning m...', 'Facts About the Ball Python (A Picture Book for Kids)', 'Python Scripting for ArcGIS', 'Digital Modulations using Python: (Color edition)', 'LEARN PYTHON PROGRAMMING: Write code from scratch in a clear & concise way, with a complet...', 'Matplotlib 2.x By Example: Multi-dimensional charts, graphs, and plots in Python', 'Practical Time Series Analysis: Master Time Series Data Processing, Visualization, and Mod...', 'Python Deep Learning Cookbook: Over 75 practical recipes on neural network modeling, reinf...', 'python crash course: The advanced language of technology. Python programming for AI, data ...', 'Learn Python 3 the Hard Way: A Very Simple Introduction to the Terrifyingly Beautiful Worl...', 'Always Be Yourself Unless You Can Be A Python Then Be A Python: Hexagonal Graph Paper Note...', 'Keras Deep Learning Cookbook: Over 30 recipes for implementing deep neural networks in Pyt...', 'Python for Data Science For Dummies, 2nd Edition (For Dummies (Computer/Tech))', 'Python Programming: A Pragmatic Approach To Programming Python for Total Beginners', 'Python Parallel Programming Cookbook', 'Python API Development Fundamentals: Develop a full-stack web application with Python and ...']\n",
      "\n",
      "[111, 237, 205, 187, 110, 245, 224, 264, 104, 408, 220, 53, 162, 340, 262, -1, 706, 215, 110, 107, 648, 248, 240, 378, 386, 39, 358, 216, 225, 334, 244, 330, 156, 320, 110, 252, 496, 128, 286, 372]\n",
      "\n",
      "[1075, 1790, 2379, 2364, 960, 1219, 8491, 3205, 4729, 3033, 2352, 1581, 1801, 5374, 4325, 4526, 7192, 14542, 960, 834, 5388, 2385, 5136, 5408, 5374, 1076, 11060, 5900, 2567, 5152, 5374, 5374, 2153, 4531, 836, 4182, 1089, 1766, 5981, 4194]\n"
     ]
    }
   ],
   "source": [
    "title  = []\n",
    "pages  = []\n",
    "price  = []\n",
    "\n",
    "for i in range(40):\n",
    "    name_node  = name_nodes[i]\n",
    "    page_node  = page_nodes[i]\n",
    "    price_node = price_nodes[i]\n",
    "    s          = parse_name_node( name_node )\n",
    "    n          = parse_page_count_node( page_node )\n",
    "    x          = parse_price_node( price_node )\n",
    "    title.append( s )\n",
    "    pages.append( n )\n",
    "    price.append( x )\n",
    "\n",
    "print(title)\n",
    "print()\n",
    "print(pages)\n",
    "print()\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Success!!  But to make our program shorter, let's do the same thing using list comprehensions. In the cell below, we'll print just `pages` and `price` to avoid the very long `title` output.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111, 237, 205, 187, 110, 245, 224, 264, 104, 408, 220, 53, 162, 340, 262, -1, 706, 215, 110, 107, 648, 248, 240, 378, 386, 39, 358, 216, 225, 334, 244, 330, 156, 320, 110, 252, 496, 128, 286, 372]\n",
      "\n",
      "[1075, 1790, 2379, 2364, 960, 1219, 8491, 3205, 4729, 3033, 2352, 1581, 1801, 5374, 4325, 4526, 7192, 14542, 960, 834, 5388, 2385, 5136, 5408, 5374, 1076, 11060, 5900, 2567, 5152, 5374, 5374, 2153, 4531, 836, 4182, 1089, 1766, 5981, 4194]\n"
     ]
    }
   ],
   "source": [
    "title  = [parse_name_node( node )  for node in name_nodes]\n",
    "pages  = [parse_page_count_node( node )  for node in page_nodes]\n",
    "price  = [parse_price_node( node)  for node in price_nodes]\n",
    "\n",
    "print(pages)\n",
    "print()\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Excellent!  One advantage of list comprehensions is that there are far fewer lines of code to read (and to debug).\n",
    "\n",
    "We could get even fancier, and parse everything using just a single line of code, like this:\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1075, 1790, 2379, 2364, 960, 1219, 8491, 3205, 4729, 3033, 2352, 1581, 1801, 5374, 4325, 4526, 7192, 14542, 960, 834, 5388, 2385, 5136, 5408, 5374, 1076, 11060, 5900, 2567, 5152, 5374, 5374, 2153, 4531, 836, 4182, 1089, 1766, 5981, 4194)\n"
     ]
    }
   ],
   "source": [
    "title,pages,price = zip( *[[parse_name_node( n ), parse_page_count_node(p), parse_price_node( pp )]  for n,p,pp in zip(name_nodes, page_nodes, price_nodes)] )\n",
    "    \n",
    "print(price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "While this type of single-line parsing is possible, you should generally avoid this style of programming, because the single-line is very long, and using many different functions, which means that it will be difficult to debug problems.\n",
    "\n",
    "OK, let's summarize our whole-page parser code, from start-to-finish:\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111, 237, 205, 187, 110, 245, 224, 264, 104, 408, 220, 53, 162, 340, 262, -1, 706, 215, 110, 107, 648, 248, 240, 378, 386, 39, 358, 216, 225, 334, 244, 330, 156, 320, 110, 252, 496, 128, 286, 372]\n",
      "\n",
      "[1075, 1790, 2379, 2364, 960, 1219, 8491, 3205, 4729, 3033, 2352, 1581, 1801, 5374, 4325, 4526, 7192, 14542, 960, 834, 5388, 2385, 5136, 5408, 5374, 1076, 11060, 5900, 2567, 5152, 5374, 5374, 2153, 4531, 836, 4182, 1089, 1766, 5981, 4194]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import lxml.html\n",
    "\n",
    "def parse_name_node(node):\n",
    "    return node.text\n",
    "\n",
    "def parse_price_node(node):\n",
    "    s = node.text\n",
    "    x = s[1:].replace(',', '')\n",
    "    return int( x )\n",
    "\n",
    "def parse_page_count_node(node):\n",
    "    s = node.text\n",
    "    if 'ページ' in s:\n",
    "        x = s.split(':')[1].split(',')[0]\n",
    "    else:\n",
    "        x = -1  # assign a value of -1 if \"ページ\" is not in the text field\n",
    "    return int( x )\n",
    "\n",
    "\n",
    "# specify data directory:\n",
    "dir0        = os.path.abspath('')              # directory in which this notebook is saved\n",
    "dirLesson   = os.path.dirname( dir0 )          # Lesson directory\n",
    "dirData     = os.path.join(dirLesson, 'Data')  # Data directory\n",
    "\n",
    "# parse the HTML file for name, page and price nodes:\n",
    "fnameHTML   = os.path.join(dirData, 'page1.html')\n",
    "tree        = lxml.html.parse(fnameHTML)\n",
    "body        = tree.find('body') \n",
    "box         = body.find_class('itemCatBox')[0]\n",
    "name_nodes  = box.find_class('name')\n",
    "page_nodes  = box.find_class('itemCatsetsumei')\n",
    "price_nodes = box.find_class('itemCatPrice')\n",
    "\n",
    "# parse the entries:\n",
    "title       = [parse_name_node( node )  for node in name_nodes]\n",
    "pages       = [parse_page_count_node( node )  for node in page_nodes]\n",
    "price       = [parse_price_node( node)  for node in price_nodes]\n",
    "\n",
    "print(pages)\n",
    "print()\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "The next notebook considers how to extend this code to multiple pages.\n",
    "\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
