{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 10:  (Working with Real Data I)  Exploring Data\n",
    "\n",
    "This lecture aims to work with large, imperfectly formatted data files. The main purpose is to explore various complications that exist in real-world data files. In particular, we will consider **parsing** real-world HTML files. \n",
    "\n",
    "**parse** = \"to analyze or separate (input, for example) into more easily processed components\" (source: [wordnik.com](https://www.wordnik.com/words/parse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "First let's import the modules we'll need for this lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import lxml.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toc\"></a>\n",
    "# Table of Contents\n",
    "\n",
    "* [Writing data](#writing)\n",
    "    * [np.savetxt](#np.savetxt)\n",
    "    * [csv.writer](#csv.writer)\n",
    "    * [csv.DictWriter](#csv.DictWriter)\n",
    "    * [open](#open)\n",
    "* [A real-world HTML example](#example)\n",
    "    * [Dataset description](#description)\n",
    "    * [Parsing a single entry](#parse-entry)\n",
    "    * [Parsing an entire page](#parse-page)\n",
    "    * [Parsing multiple pages](#parse-pages)\n",
    "    * [Writing results](#parse-write)\n",
    "    * [Full standalone script](#parse-full)\n",
    "* [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a name=\"example\"></a>\n",
    "# A real-world HTML example\n",
    "[Back to Table of Contents](#toc)\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "⚠️ **NOTE!**  &nbsp; &nbsp; All data files used in this example are available in the `kakaku-com` folder.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a name=\"description\"></a>\n",
    "## Dataset description\n",
    "[Back to Table of Contents](#toc)\n",
    "<br>\n",
    "\n",
    "This folder contains 5 HTML files from kakaku.com\n",
    "\n",
    "The files contain search results for `python` in the category \"和書\" (Western books)\n",
    "\n",
    "An example URL is:\n",
    "\n",
    "https://kakaku.com/book/ss_0010_0001/0028/python/search_itemlist.aspx?ssi_kw=python&ssi_page=5\n",
    "\n",
    "\n",
    "The first three search resutls from `page1.html` are depicted below.\n",
    "\n",
    "The goal of this example will be to parse all five HTML pages, extracting the title and price of each book.  There are 40 books per page, so we will extract a total of 200 titles and 200 prices.\n",
    "\n",
    "<br>\n",
    "<img src=\"img/ss0.png\" alt=\"screenshot\" width=700 />\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a name=\"parse-entry\"></a>\n",
    "## Parsing a single entry\n",
    "[Back to Table of Contents](#toc)\n",
    "<br>\n",
    "\n",
    "Let's open the HTML file in a **text editor** (e.g. Notepad), and find where the data are stored for the first entry. The easiest way to do this is to search the text file for a word in the title, for example \"Django\".  This search will take us to a spot in the file as depicted below.\n",
    "\n",
    "<br>\n",
    "<img src=\"img/ss1.png\" alt=\"screenshot\" width=700 />\n",
    "<br>\n",
    "\n",
    "Note that, near the bottom of this image, there is a `<span>` tag that contans the title of the first book: <span style=\"color:red\">\"Django: Django , Web framework for Python\"</span>.\n",
    "\n",
    "Note also that the class of this `<span>` tag is `\"name\"`.\n",
    "\n",
    "We can use the `find_class` function to extract this title as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "import lxml.html\n",
    "\n",
    "fnameHTML  = os.path.join(dir0, 'kakaku-com', 'page1.html')\n",
    "tree       = lxml.html.parse(fnameHTML)\n",
    "\n",
    "body       = tree.find('body') \n",
    "name_nodes = body.find_class('name')\n",
    "\n",
    "print( len(name_nodes) )   # number of name nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found 40 name nodes! Let's check the text stored in the first one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Django: Django , Web framework for Python\n"
     ]
    }
   ],
   "source": [
    "name  = name_nodes[0].text\n",
    "\n",
    "print( name )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent!  We have extracted the title of the first book.\n",
    "\n",
    "How about its price?\n",
    "\n",
    "If you look a few lines further in the file, you will see the following:\n",
    "\n",
    "<br>\n",
    "<img src=\"img/ss2.png\" alt=\"screenshot\" width=700 />\n",
    "<br>\n",
    "\n",
    "Note that the price is saved in the text field of a `<span>` tag with the class: `\"itemCatPrice\"`.\n",
    "\n",
    "We can retrieve all `\"itemCatPrice\"` nodes like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "price_nodes = body.find_class('itemCatPrice')\n",
    "\n",
    "print( len(price_nodes) )   # number of name nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh no!  There are 50 prices, but only 40 titles!  What has happened?\n",
    "\n",
    "If you look near the top of the page you'll see a horizontal preview bar with prices indicated.\n",
    "\n",
    "\n",
    "<br>\n",
    "<img src=\"img/ss3.png\" alt=\"screenshot\" width=700 />\n",
    "<br>\n",
    "\n",
    "\n",
    "If you search (from the beginning of the HTML source code) for the first instance of `itemCatPrice`, you'll find that it appears in a section called the `sponsorShopArea`.\n",
    "\n",
    "\n",
    "<br>\n",
    "<img src=\"img/ss4.png\" alt=\"screenshot\" width=700 />\n",
    "<br>\n",
    "\n",
    "Let's check how many `itemCatPrice` items appear inside this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "shop_area = body.find_class('sponsorShopArea is-grid is-imgSmall')[0]\n",
    "\n",
    "nodes     = shop_area.find_class('itemCatPrice')\n",
    "\n",
    "print( len(nodes) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! There are 10 `itemCatPrice` nodes in this section, which means that the other 40 nodes must be in a different section.\n",
    "\n",
    "If we keep searching the HTML source code for the 11th instance of `itemCatPrice`, we'll find that it lies in a section called `itemCatBox`.\n",
    "\n",
    "<br>\n",
    "<img src=\"img/ss5.png\" alt=\"screenshot\" width=700 />\n",
    "<br>\n",
    "\n",
    "Let's check how many `itemCatPrice` items appear inside this `itemCatBox` section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "box   = body.find_class('itemCatBox')[0]\n",
    "\n",
    "nodes = box.find_class('itemCatPrice')\n",
    "\n",
    "print( len(nodes) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! We have found the 40 instances we were looking for.\n",
    "\n",
    "Although we've already found the book name nodes, let's check if we can also find them inside the `itemCatBox` section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "nodes = box.find_class('name')\n",
    "\n",
    "print( len(nodes) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent again!  We used `body.find_class` above, but that was only good for the `'name'` nodes, and not for the `'itemCatPrice'` nodes.  We now know that we can use `box.find_class` for both. For consistencey let's summarize using only `box.find_class`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "import lxml.html\n",
    "\n",
    "fnameHTML   = os.path.join(dir0, 'kakaku-com', 'page1.html')\n",
    "tree        = lxml.html.parse(fnameHTML)\n",
    "body        = tree.find('body') \n",
    "box         = body.find_class('itemCatBox')[0]\n",
    "name_nodes  = box.find_class('name')\n",
    "price_nodes = box.find_class('itemCatPrice')\n",
    "\n",
    "print( len(name_nodes) )    # number of name nodes\n",
    "print( len(price_nodes) )   # number of price nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, let's extract the name and price for a single book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Django: Django , Web framework for Python\n",
      "￥1,075\n"
     ]
    }
   ],
   "source": [
    "name_node   = name_nodes[0]\n",
    "price_node  = price_nodes[0]\n",
    "\n",
    "print(name_node.text)\n",
    "print(price_node.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, this matches the first entry in the HTML page (see first screenshot above).\n",
    "\n",
    "However, since we'll later want to work with the numbers, it would be more convenient to save the price as `1075` than as `¥1,075`. To do this we can do the following:\n",
    "\n",
    "* Ignore the first character (which will always be `¥`)\n",
    "* Remove all `,` characters\n",
    "* Convert the string object to an integer object\n",
    "\n",
    "This can be achieved in Python like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "￥1,075 <class 'str'>\n",
      "1,075 <class 'str'>\n",
      "1075 <class 'str'>\n",
      "1075 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "s0  = price_node.text       # original string\n",
    "s1  = s0[1:]                # discard the first character\n",
    "s2  = s1.replace(',', '')   # replace all \",\" characters with empty characters\n",
    "x   = int( s2 )             # convert the resulting string to an integer\n",
    "\n",
    "print( s0, type(s0) )\n",
    "print( s1, type(s1) )\n",
    "print( s2, type(s2) )\n",
    "print( x, type(x) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could instead achieve the same result on a single line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1075\n"
     ]
    }
   ],
   "source": [
    "x  = int( price_node.text[1:].replace(',', '') )\n",
    "\n",
    "print( x )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finished!  We have successfully parsed the first book on **page1.html**.\n",
    "\n",
    "Let's proceed to parse the entire page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a name=\"parse-page\"></a>\n",
    "## Parsing an entire page\n",
    "[Back to Table of Contents](#toc)\n",
    "<br>\n",
    "\n",
    "A good general strategy is to create a separate function for each part of the parsing process.\n",
    "\n",
    "Let's first create functions to parse name nodes and price nodes, then test them on the first book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Django: Django , Web framework for Python\n",
      "1075\n"
     ]
    }
   ],
   "source": [
    "import lxml.html\n",
    "\n",
    "def parse_name_node(node):\n",
    "    return node.text\n",
    "\n",
    "def parse_price_node(node):\n",
    "    s = node.text\n",
    "    x = int( s[1:].replace(',', '') )\n",
    "    return x\n",
    "\n",
    "\n",
    "fnameHTML   = os.path.join(dir0, 'kakaku-com', 'page1.html')\n",
    "tree        = lxml.html.parse(fnameHTML)\n",
    "body        = tree.find('body') \n",
    "box         = body.find_class('itemCatBox')[0]\n",
    "name_nodes  = box.find_class('name')\n",
    "price_nodes = box.find_class('itemCatPrice')\n",
    "\n",
    "\n",
    "name        = parse_name_node( name_nodes[0] )\n",
    "price       = parse_price_node( price_nodes[0] )\n",
    "\n",
    "print(name)\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  It will now be relatively easy to parse the entire page.  All we need to do is cycle through all of the nodes, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Django: Django , Web framework for Python', 'PYTHON PROGRAMMING ADVANCED: The Guide for Data Analysis and Data Science. Discover Machin...', \"Python Data Analytics: The Beginner's Real World Crash Course\", 'Programacion Con Python: Guia Completa para Principiantes   Aprende sobre Los Reinos De La...', 'Snake Reptile Week Planner Weekly Organizer Calendar 2020 / 2021 - Green Tree Python: Cute...', 'Python for Everybody: Exploring Data in Python 3', 'Python language for your growing children and for beginners', '101 Extra Python Challenges with Solutions / Code Listings', 'CIE IGCSE COMPUTER SCIENCE 9-1 SYLLABUS 2020-2021: PAPER 2 SPECIFICATION BOOK WITH FULL PY...', 'Computer Programming And Cyber Security for Beginners: This Book Includes: Python Machine ...', 'Python GUI: For Signal and Image Processing', 'Machine Learning with Scikit-Learn and TensorFlow: Deep Learning with Python (Random Fores...', 'Python Machine Learning: How to learn Machine Learning with Python. The Complete Guide to ...', 'Python Robotics Projects: Build smart and collaborative robots using Python', 'Complex Network Analysis in Python: Recognize - Construct - Visualize - Analyze - Interpre...', 'Python Projects【楽天海外直送】【英語の本】【洋書】', 'Python Cookbook: Recipes for Mastering Python 3', 'Simulating Nonlinear Circuits with Python Power Electronics: An Open-Source Simulator, Bas...', 'Snake Reptile Week Planner Weekly Organizer Calendar 2020 / 2021 - Golden Python: Cute Wil...', 'Always Be Yourself Unless You Can Be A Python Then Be A Python: Bucket List Journal', \"Programming in Python 3: A Complete Introduction to the Python Language (Developer's Libra...\", 'Python Crash Course: Strategy guide for beginners with examples and practical exercises (P...', \"Learn More Python 3 the Hard Way: The Next Step for New Python Programmers (Zed Shaw's Har...\", 'Python Machine Learning Blueprints: Put your machine learning concepts to the test by deve...', 'Hands-On Unsupervised Learning with Python: Implement machine learning and deep learning m...', 'Facts About the Ball Python (A Picture Book for Kids)', 'Python Scripting for ArcGIS', 'Digital Modulations using Python: (Color edition)', 'LEARN PYTHON PROGRAMMING: Write code from scratch in a clear & concise way, with a complet...', 'Matplotlib 2.x By Example: Multi-dimensional charts, graphs, and plots in Python', 'Practical Time Series Analysis: Master Time Series Data Processing, Visualization, and Mod...', 'Python Deep Learning Cookbook: Over 75 practical recipes on neural network modeling, reinf...', 'python crash course: The advanced language of technology. Python programming for AI, data ...', 'Learn Python 3 the Hard Way: A Very Simple Introduction to the Terrifyingly Beautiful Worl...', 'Always Be Yourself Unless You Can Be A Python Then Be A Python: Hexagonal Graph Paper Note...', 'Keras Deep Learning Cookbook: Over 30 recipes for implementing deep neural networks in Pyt...', 'Python for Data Science For Dummies, 2nd Edition (For Dummies (Computer/Tech))', 'Python Programming: A Pragmatic Approach To Programming Python for Total Beginners', 'Python Parallel Programming Cookbook', 'Python API Development Fundamentals: Develop a full-stack web application with Python and ...']\n",
      "\n",
      "[1075, 1790, 2379, 2364, 960, 1219, 8491, 3205, 4729, 3033, 2352, 1581, 1801, 5374, 4325, 4526, 7192, 14542, 960, 834, 5388, 2385, 5136, 5408, 5374, 1076, 11060, 5900, 2567, 5152, 5374, 5374, 2153, 4531, 836, 4182, 1089, 1766, 5981, 4194]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "names  = []\n",
    "prices = []\n",
    "\n",
    "for i in range(40):\n",
    "    name_node  = name_nodes[i]\n",
    "    price_node = price_nodes[i]\n",
    "    name       = parse_name_node( name_node )\n",
    "    price      = parse_price_node( price_node )\n",
    "    names.append( name )\n",
    "    prices.append( price )\n",
    "\n",
    "print(names)\n",
    "print()\n",
    "print(prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can achieve the same result with briefer, slightly more clever Python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1075, 1790, 2379, 2364, 960, 1219, 8491, 3205, 4729, 3033, 2352, 1581, 1801, 5374, 4325, 4526, 7192, 14542, 960, 834, 5388, 2385, 5136, 5408, 5374, 1076, 11060, 5900, 2567, 5152, 5374, 5374, 2153, 4531, 836, 4182, 1089, 1766, 5981, 4194)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "names,prices = zip( *[[parse_name_node( n ), parse_price_node( p )]  for n,p in zip(name_nodes, price_nodes)] )\n",
    "    \n",
    "print(prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a name=\"parse-pages\"></a>\n",
    "## Parsing multiple pages\n",
    "[Back to Table of Contents](#toc)\n",
    "<br>\n",
    "\n",
    "To parse multiple pages, let's first move our single-page parsing code into a custom function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1075, 1790, 2379, 2364, 960, 1219, 8491, 3205, 4729, 3033, 2352, 1581, 1801, 5374, 4325, 4526, 7192, 14542, 960, 834, 5388, 2385, 5136, 5408, 5374, 1076, 11060, 5900, 2567, 5152, 5374, 5374, 2153, 4531, 836, 4182, 1089, 1766, 5981, 4194]\n"
     ]
    }
   ],
   "source": [
    "def parse_page(fnameHTML):\n",
    "    tree         = lxml.html.parse(fnameHTML)\n",
    "    body         = tree.find('body') \n",
    "    box          = body.find_class('itemCatBox')[0]\n",
    "    name_nodes   = box.find_class('name')\n",
    "    price_nodes  = box.find_class('itemCatPrice')\n",
    "    names,prices = zip( *[[parse_name_node( n ), parse_price_node( p )]  for n,p in zip(name_nodes, price_nodes)] )\n",
    "    return list(names), list(prices)\n",
    "\n",
    "fnameHTML    = os.path.join(dir0, 'kakaku-com', 'page1.html')\n",
    "names,prices = parse_page(fnameHTML)\n",
    "\n",
    "print(prices)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  It will now be relatively easy to parse multiple pages. We just need to:\n",
    "\n",
    "* iteratively update the HTML file names\n",
    "* assemble all names and prices from each page into a larger list\n",
    "\n",
    "One way to do this is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "\n",
      "[1075, 1790, 2379, 2364, 960, 1219, 8491, 3205, 4729, 3033, 2352, 1581, 1801, 5374, 4325, 4526, 7192, 14542, 960, 834, 5388, 2385, 5136, 5408, 5374, 1076, 11060, 5900, 2567, 5152, 5374, 5374, 2153, 4531, 836, 4182, 1089, 1766, 5981, 4194, 3447, 734, 8621, 8976, 1890, 4600, 1234, 5053, 2363, 1320, 1759, 2358, 734, 1770, 1650, 6336, 5393, 1906, 5971, 836, 2066, 2402, 4307, 2399, 2094, 3582, 2329, 14055, 2389, 1905, 5971, 5169, 3607, 5374, 2364, 4179, 5413, 769, 4927, 11281, 1804, 1539, 2085, 3751, 3607, 2987, 1067, 2984, 1190, 474, 1949, 11770, 5971, 834, 18498, 2045, 3251, 815, 2261, 2400, 1551, 2554, 1965, 838, 2388, 5044, 837, 4775, 1018, 12320, 4190, 1164, 2280, 469, 3706, 5354, 269, 5374, 9809, 1803, 3556, 5374, 816, 5080, 2069, 1219, 3322, 1430, 2461, 1099, 7456, 2384, 2200, 4583, 2563, 7457, 8360, 5971, 2045, 3425, 4012, 2277, 2286, 1189, 6368, 2264, 2079, 5019, 4776, 4776, 1936, 1441, 2767, 2143, 3978, 7218, 4576, 5969, 4777, 1099, 3072, 414, 2072, 2207, 2340, 5772, 4470, 2400, 3045, 4902, 2373, 835, 5374, 5971, 5395, 1544, 776, 1422, 6747, 1800, 3584, 4550, 7642, 5374, 1552, 5794, 2389, 5176, 4187, 3589, 3715, 4941, 1188, 2092, 4201, 989, 838, 3698, 956, 14047]\n"
     ]
    }
   ],
   "source": [
    "names  = []\n",
    "prices = []\n",
    "for i in range(5):\n",
    "    fnameHTML = os.path.join(dir0, 'kakaku-com', f'page{i+1}.html')\n",
    "    n,p       = parse_page(fnameHTML)\n",
    "    names    += n\n",
    "    prices   += p\n",
    "\n",
    "print( len(prices) )\n",
    "print()\n",
    "print(prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent!  We now have names and prices for all 200 books from the five HTML pages.\n",
    "\n",
    "These data are difficult to visualize in Python, so let's save them to CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a name=\"parse-write\"></a>\n",
    "## Writing results\n",
    "[Back to Table of Contents](#toc)\n",
    "<br>\n",
    "\n",
    "The `names` variable from the previous section is a list of strings, but the `prices` variable is a list of integers. One way to save these data easily is to use `csv.writer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir0     = os.path.abspath('')       # directory in which this notebook is saved\n",
    "fnameCSV = os.path.join( dir0, 'kakaku-prices.csv' )\n",
    "\n",
    "with open(fnameCSV, 'w') as fid:     # open in write mode\n",
    "    writer = csv.writer(fid)         # create a writer object\n",
    "    labels = ['Num','Name','Price']  # column labels\n",
    "    writer.writerow( labels )        # write column labels\n",
    "    for i,(n,p) in enumerate(zip(names,prices)):   # cycle through rows\n",
    "        writer.writerow( [i+1,n,p] ) # write the current row to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the cell above executed without errors, then there should be a new file called **kakaku-prices.csv** in the same folder as this workbook. Check that it contains titles and prices for 200 books.\n",
    "\n",
    "Last, let's assemble all of our code into a single script (i.e., a single cell in Jupyter that can be run by itself)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a name=\"parse-full\"></a>\n",
    "## Full standalone script\n",
    "[Back to Table of Contents](#toc)\n",
    "<br>\n",
    "\n",
    "\n",
    "The cell below contains the full code for this kakaku.com example, including a plot of the distribution of prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEJCAYAAACT/UyFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAATxklEQVR4nO3df7DldX3f8edLEH9C2JULswXpYqVU2hmB3hgMidOAEpBUSBop1qk7CdOdNJpKbVM3daa1M+3M0jZR26Y6W7GuDlF+KAMJiUo3aJoZgy4ICi5kgYIhbHYXlILRiQXf/eN8Vs7evffu3d37PWfvfp6PmTPn+/2c74/393t3X+d7Puf7/Z5UFZKkfrxg2gVIkibL4Jekzhj8ktQZg1+SOmPwS1JnDH5J6sxgwZ/kjCR3jz2eTnJVktVJbkuyvT2vGqoGSdK+Monz+JMcBfw58BPAO4FvV9XGJBuAVVX13sGLkCQBkwv+C4F/W1XnJXkA+HtVtSPJGuCLVXXGYvOfcMIJtXbt2sHrlKQjyZ133vlEVc3MbT96Quu/AvhUGz6pqnYAtPA/cb4ZkqwH1gOceuqpbN26dSKFStKRIsmj87UP/uVukmOAtwA3HMh8VbWpqmaranZmZp83LEnSQZrEWT0XA3dV1c42vrN18dCed02gBklSM4ngfxvPd/MA3AKsa8PrgJsnUIMkqRk0+JO8FHgT8Nmx5o3Am5Jsb69tHLIGSdLeBv1yt6q+B7xiTtuTwAVDrleStDCv3JWkzhj8ktQZg1+SOmPwS1JnJnXl7tSs3XDrVNb7yMZLprJeSdofj/glqTMGvyR1xuCXpM4Y/JLUGYNfkjpj8EtSZwx+SeqMwS9JnTH4JakzBr8kdcbgl6TOGPyS1BmDX5I6Y/BLUmcMfknqjMEvSZ0x+CWpM4MGf5Ljk9yY5P4k25K8PsnqJLcl2d6eVw1ZgyRpb0Mf8X8I+FxV/S3gtcA2YAOwpapOB7a0cUnShAwW/EmOA94AXANQVT+oqqeAS4HNbbLNwGVD1SBJ2teQR/yvAnYD/zPJ15J8NMnLgJOqagdAez5xvpmTrE+yNcnW3bt3D1imJPVlyOA/GjgH+HBVnQ38JQfQrVNVm6pqtqpmZ2ZmhqpRkrozZPA/BjxWVXe08RsZvRHsTLIGoD3vGrAGSdIcgwV/Vf0F8GdJzmhNFwDfBG4B1rW2dcDNQ9UgSdrX0QMv/9eAa5McAzwM/BKjN5vrk1wJfAt468A1SJLGDBr8VXU3MDvPSxcMuV5J0sK8cleSOmPwS1JnDH5J6ozBL0mdMfglqTMGvyR1xuCXpM4Y/JLUGYNfkjpj8EtSZwx+SeqMwS9JnTH4JakzQ9+WuVtrN9w6tXU/svGSqa1b0uHPI35J6ozBL0mdMfglqTMGvyR1xuCXpM4Y/JLUGYNfkjpj8EtSZwa9gCvJI8AzwHPAs1U1m2Q1cB2wFngEuLyqvjNkHZKk503iiP9nquqsqppt4xuALVV1OrCljUuSJmQaXT2XApvb8GbgsinUIEndGjr4C/hCkjuTrG9tJ1XVDoD2fOJ8MyZZn2Rrkq27d+8euExJ6sfQN2k7r6oeT3IicFuS+5c6Y1VtAjYBzM7O1lAFSlJvBj3ir6rH2/Mu4CbgdcDOJGsA2vOuIWuQJO1tsOBP8rIkx+4ZBi4E7gVuAda1ydYBNw9VgyRpX0N29ZwE3JRkz3p+p6o+l+SrwPVJrgS+Bbx1wBokSXMMFvxV9TDw2nnanwQuGGq9kqTF+QtcR6Bp/fqXv/wlrQzeskGSOmPwS1JnDH5J6ozBL0mdMfglqTMGvyR1xuCXpM4Y/JLUGYNfkjpj8EtSZwx+SeqMwS9JnTH4JakzBr8kdcbgl6TOGPyS1BmDX5I6Y/BLUmcMfknqjMEvSZ0x+CWpM4MHf5Kjknwtye+18dOS3JFke5LrkhwzdA2SpOdN4oj/3cC2sfGrgQ9U1enAd4ArJ1CDJKkZNPiTnAJcAny0jQc4H7ixTbIZuGzIGiRJexv6iP+DwL8CftjGXwE8VVXPtvHHgJPnmzHJ+iRbk2zdvXv3wGVKUj8GC/4kPwfsqqo7x5vnmbTmm7+qNlXVbFXNzszMDFKjJPXo6AGXfR7wliRvBl4MHMfoE8DxSY5uR/2nAI8PWIMkaY4lHfEnOW8pbeOq6jeq6pSqWgtcAfxhVb0duB34xTbZOuDmA6pYknRIltrV81+X2LYU7wXek+RBRn3+1xzkciRJB2HRrp4krwd+EphJ8p6xl44DjlrqSqrqi8AX2/DDwOsOtFBJ0vLYXx//McDL23THjrU/zfPdNZKkFWTR4K+qLwFfSvLxqnp0QjVJkga01LN6XpRkE7B2fJ6qOn+IoiRJw1lq8N8AfITRFbjPDVeOJGloSw3+Z6vqw4NWIkmaiKWezvm7SX41yZokq/c8Bq1MkjSIpR7xr2vPvz7WVsCrlrccSdLQlhT8VXXa0IVIkiZjScGf5B3ztVfVJ5a3HEnS0Jba1fPjY8MvBi4A7gIMfklaYZba1fNr4+NJfgz45CAVSZIGdbD34/8ecPpyFiJJmoyl9vH/Ls//YMpRwGuA64cqSpI0nKX28f/nseFngUer6rEB6pEkDWxJXT3tZm33M7pD5yrgB0MWJUkazlJ/gety4CvAW4HLgTuSeFtmSVqBltrV8z7gx6tqF0CSGeB/ATcOVZgkaRhLPavnBXtCv3nyAOaVJB1GlnrE/7kknwc+1cb/IfD7w5QkSRrS/n5z99XASVX160l+AfgpIMCXgWsnUJ8kaZntr7vmg8AzAFX12ap6T1X9c0ZH+x8cujhJ0vLbX/Cvraqvz22sqq2MfoZRkrTC7C/4X7zIay9ZbMYkL07ylST3JLkvyb9r7acluSPJ9iTXJTnmQIuWJB28/QX/V5P8k7mNSa4E7tzPvH8FnF9VrwXOAi5Kci5wNfCBqjod+A5w5YGXLUk6WPs7q+cq4KYkb+f5oJ8FjgF+frEZq6qA77bRF7ZHAecD/6i1bwbeD/h7vpI0IYsGf1XtBH4yyc8Af6c131pVf7iUhSc5itEbxquB3wYeAp6qqmfbJI8BJy8w73pgPcCpp566lNVJkpZgqffjvx24/UAXXlXPAWclOR64idFdPfeZbIF5NwGbAGZnZ+edRpJ04CZy9W1VPQV8ETgXOD7JnjecU4DHJ1GDJGlksOBPMtOO9EnyEuCNwDZGnxz23OBtHXDzUDVIkva11Fs2HIw1wObWz/8C4Pqq+r0k3wQ+neTfA18DrhmwBknSHIMFf7vw6+x52h8GXjfUeiVJi/MOm5LUGYNfkjpj8EtSZwx+SeqMwS9JnTH4JakzBr8kdcbgl6TOGPyS1BmDX5I6Y/BLUmcMfknqjMEvSZ0x+CWpMwa/JHXG4Jekzhj8ktQZg1+SOmPwS1JnDH5J6ozBL0mdMfglqTODBX+SVya5Pcm2JPcleXdrX53ktiTb2/OqoWqQJO1ryCP+Z4F/UVWvAc4F3pnkTGADsKWqTge2tHFJ0oQMFvxVtaOq7mrDzwDbgJOBS4HNbbLNwGVD1SBJ2tdE+viTrAXOBu4ATqqqHTB6cwBOXGCe9Um2Jtm6e/fuSZQpSV0YPPiTvBz4DHBVVT291PmqalNVzVbV7MzMzHAFSlJnBg3+JC9kFPrXVtVnW/POJGva62uAXUPWIEna25Bn9QS4BthWVb819tItwLo2vA64eagaJEn7OnrAZZ8H/GPgG0nubm3/GtgIXJ/kSuBbwFsHrEGSNMdgwV9VfwxkgZcvGGq9kqTFeeWuJHXG4Jekzhj8ktSZIb/cVWfWbrh1aut+ZOMlU1u3tNJ4xC9JnTH4JakzBr8kdcbgl6TOGPyS1BmDX5I6Y/BLUmcMfknqjMEvSZ0x+CWpMwa/JHXG4Jekzhj8ktQZg1+SOmPwS1JnDH5J6ozBL0mdMfglqTODBX+SjyXZleTesbbVSW5Lsr09rxpq/ZKk+Q15xP9x4KI5bRuALVV1OrCljUuSJmiw4K+qPwK+Paf5UmBzG94MXDbU+iVJ85t0H/9JVbUDoD2fuNCESdYn2Zpk6+7duydWoCQd6Q7bL3eralNVzVbV7MzMzLTLkaQjxqSDf2eSNQDtedeE1y9J3Zt08N8CrGvD64CbJ7x+SerekKdzfgr4MnBGkseSXAlsBN6UZDvwpjYuSZqgo4dacFW9bYGXLhhqnZKk/Ttsv9yVJA3D4Jekzhj8ktQZg1+SOmPwS1JnDH5J6ozBL0mdMfglqTMGvyR1ZrArd6VJWrvh1qms95GNl0xlvdKh8Ihfkjpj8EtSZwx+SeqMwS9JnTH4JakzBr8kdcbTOaUValqnsE6Tp88uD4/4JakzBr8kdcauHukQ9NjdopXPI35J6ozBL0mdmUpXT5KLgA8BRwEfraqN06hDkpbiSLsJ4MSP+JMcBfw2cDFwJvC2JGdOug5J6tU0unpeBzxYVQ9X1Q+ATwOXTqEOSerSNLp6Tgb+bGz8MeAn5k6UZD2wvo1+N8kDS1z+CcATh1Th8FZCjWCdy20l1HlY15irfzR4WNc55pDqHNveg/XX52ucRvBnnrbap6FqE7DpgBeebK2q2YMpbFJWQo1gncttJdS5EmoE6zxU0+jqeQx45dj4KcDjU6hDkro0jeD/KnB6ktOSHANcAdwyhTokqUsT7+qpqmeTvAv4PKPTOT9WVfct4yoOuHtoClZCjWCdy20l1LkSagTrPCSp2qd7XZJ0BPPKXUnqjMEvSZ05YoI/yUVJHkjyYJINE173K5PcnmRbkvuSvLu1vz/Jnye5uz3ePDbPb7RaH0jys5PajiSPJPlGq2dra1ud5LYk29vzqtaeJP+l1fL1JOeMLWddm357knXLXOMZY/vs7iRPJ7nqcNifST6WZFeSe8falm3/Jfm77e/zYJt3vtOfD7bO/5Tk/lbLTUmOb+1rk3x/bL9+ZH/1LLTNy1Djsv2NMzqB5I5W43UZnUxywBao87qxGh9Jcndrn8q+PGBVteIfjL4kfgh4FXAMcA9w5gTXvwY4pw0fC/wpo9tRvB/4l/NMf2ar8UXAaa32oyaxHcAjwAlz2v4jsKENbwCubsNvBv6A0bUX5wJ3tPbVwMPteVUbXjXg3/YvGF2IMvX9CbwBOAe4d4j9B3wFeH2b5w+Ai5exzguBo9vw1WN1rh2fbs5y5q1noW1ehhqX7W8MXA9c0YY/AvzT5dqXc17/TeDfTHNfHujjSDnin+ptIKpqR1Xd1YafAbYxukJ5IZcCn66qv6qq/wM8yGgbprUdlwKb2/Bm4LKx9k/UyJ8AxydZA/wscFtVfbuqvgPcBlw0UG0XAA9V1aOLTDOx/VlVfwR8e571H/L+a68dV1VfrlEKfGJsWYdcZ1V9oaqebaN/wugamgXtp56FtvmQalzEAf2N29H0+cCNh1Lj/ups67kc+NRiyxh6Xx6oIyX457sNxGLBO5gka4GzgTta07vaR+uPjX2EW6jeSWxHAV9IcmdGt8UAOKmqdsDoTQw48TCoc48r2Ps/1eG2P2H59t/JbXjoegF+mdFR5x6nJflaki8l+enWtlg9C23zcliOv/ErgKfG3uiG2pc/Deysqu1jbYfTvpzXkRL8S7oNxOBFJC8HPgNcVVVPAx8G/gZwFrCD0UdCWLjeSWzHeVV1DqO7o74zyRsWmXaaddL6ZN8C3NCaDsf9uZgDrWtS+/V9wLPAta1pB3BqVZ0NvAf4nSTHTaqeOZbrbzyp2t/G3gcmh9O+XNCREvxTvw1EkhcyCv1rq+qzAFW1s6qeq6ofAv+D0cfSxeodfDuq6vH2vAu4qdW0s30U3fORdNe062wuBu6qqp2t5sNufzbLtf8eY+/ul2Wvt32R/HPA21uXA6375Mk2fCejPvO/uZ96FtrmQ7KMf+MnGHWtHT2nfdm0Zf8CcN1Y/YfNvlzMkRL8U70NROvnuwbYVlW/Nda+Zmyynwf2nBVwC3BFkhclOQ04ndEXP4NuR5KXJTl2zzCjL/vubevYc2bJOuDmsTrfkZFzgf/bPop+Hrgwyar2UfzC1rbc9jqaOtz255hl2X/ttWeSnNv+Tb1jbFmHLKMfQHov8Jaq+t5Y+0xGv5NBklcx2n8P76eehbb5UGtclr9xe1O7HfjF5a5xzBuB+6vqR104h9O+XNTQ3x5P6sHoDIo/ZfQO+74Jr/unGH1s+zpwd3u8Gfgk8I3WfguwZmye97VaH2DszI0ht4PRmQ/3tMd9e5bPqD90C7C9Pa9u7WH0ozkPte2YHVvWLzP6gu1B4JcG2KcvBZ4Efmysber7k9Eb0Q7g/zE6irtyOfcfMMso7B4C/hvt6vplqvNBRv3he/6NfqRN+w/av4d7gLuAv7+/ehba5mWocdn+xu3f+1fadt8AvGi59mVr/zjwK3Omncq+PNCHt2yQpM4cKV09kqQlMvglqTMGvyR1xuCXpM4Y/JLUGYNfmiPJc+3OivcmuSHJSxeY7vfT7nAprSSezinNkeS7VfXyNnwtcGftfWFeGP3f+eG0apQOhUf80uL+N/DqjO6zvi3Jf2d0Yc4rM7oP+wkASd7Rbix2T5JPtraZJJ9J8tX2OG+K2yH9yMR/bF1aKdq9WC4GPteazmB0le2vttf3TPe3GV1Vel5VPZFkdZv+Q8AHquqPk5zK6FYNr5ngJkjzMvilfb0k7ReVGB3xXwP8NeDRGt1Xf67zgRur6gmAqtpz7/Y3Amfm+R/ROi7JsTX6zQZpagx+aV/fr6qzxhtaeP/lAtOH+W+x+wLg9VX1/eUtTzo09vFLh24LcHmSV8DoN1Rb+xeAd+2ZKMlZ88wrTZzBLx2iqroP+A/Al5LcA+w5A+ifAbPtS99vAr8yrRqlcZ7OKUmd8Yhfkjpj8EtSZwx+SeqMwS9JnTH4JakzBr8kdcbgl6TO/H8l4fulf0KYDgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import lxml.html\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def parse_name_node(node):\n",
    "    return node.text\n",
    "\n",
    "\n",
    "def parse_price_node(node):\n",
    "    s = node.text\n",
    "    x = int( s[1:].replace(',', '') )\n",
    "    return x\n",
    "\n",
    "\n",
    "def parse_page(fnameHTML):\n",
    "    tree         = lxml.html.parse(fnameHTML)\n",
    "    body         = tree.find('body') \n",
    "    box          = body.find_class('itemCatBox')[0]\n",
    "    name_nodes   = box.find_class('name')\n",
    "    price_nodes  = box.find_class('itemCatPrice')\n",
    "    names,prices = zip( *[[parse_name_node( n ), parse_price_node( p )]  for n,p in zip(name_nodes, price_nodes)] )\n",
    "    return list(names), list(prices)\n",
    "\n",
    "\n",
    "def parse_all(dirname):\n",
    "    names  = []\n",
    "    prices = []\n",
    "    for i in range(5):\n",
    "        fnameHTML = os.path.join(dirname, f'page{i+1}.html')\n",
    "        n,p       = parse_page(fnameHTML)\n",
    "        names    += n\n",
    "        prices   += p\n",
    "    return names,prices\n",
    "\n",
    "\n",
    "def write_results(fnameCSV, names, prices):\n",
    "    with open(fnameCSV, 'w') as fid:     # open in write mode\n",
    "        writer = csv.writer(fid)         # create a writer object\n",
    "        labels = ['Num','Name','Price']  # column labels\n",
    "        writer.writerow( labels )        # write column labels\n",
    "        for i,(n,p) in enumerate(zip(names,prices)):   # cycle through rows\n",
    "            writer.writerow( [i+1,n,p] ) # write the current row to file\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parse all data:\n",
    "dir0         = os.path.abspath('')                        # directory in which this notebook is saved\n",
    "dirDATA      = os.path.join(dir0, 'kakaku-com')           # directory to parse\n",
    "names,prices = parse_all(dirDATA)\n",
    "\n",
    "# Write the results:\n",
    "fnameCSV     = os.path.join( dir0, 'kakaku-prices.csv' )  # results file name\n",
    "write_results(fnameCSV, names, prices)\n",
    "\n",
    "# Plot the distribution of prices\n",
    "plt.figure()\n",
    "plt.hist(prices)\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a name=\"summary\"></a>\n",
    "# Summary\n",
    "[Back to Table of Contents](#toc)\n",
    "\n",
    "* Useful Python functions for writing data are:\n",
    "\n",
    "    * `np.savetxt`\n",
    "    *  `csv.writer`\n",
    "    * `open`\n",
    "\n",
    "* This notebook has demonstrated how to **parse** a relatively complex real-workd HTML structure, and how to extract desired data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
