{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#54B1FF\">Exploring Data:</span> &nbsp; <span style=\"color:#1B3EA9\"><b>Write Results</b></span>\n",
    "\n",
    "<br>\n",
    "\n",
    "In the previous notebooks in this lesson we saw how to parse multiple entries from multiple pages. In this notebook we'll consider how to save the parsed results.\n",
    "\n",
    "As general data analysis rules:\n",
    "* Separate your **parsing** code from your **analysis** code\n",
    "* Save parsed results separately from the original data files, so that your analysis code can focus on the parsed results. \n",
    "\n",
    "Let's first assemble our multi-page parsing code, and parse all pages:\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "\n",
      "[1075, 1790, 2379, 2364, 960, 1219, 8491, 3205, 4729, 3033, 2352, 1581, 1801, 5374, 4325, 4526, 7192, 14542, 960, 834, 5388, 2385, 5136, 5408, 5374, 1076, 11060, 5900, 2567, 5152, 5374, 5374, 2153, 4531, 836, 4182, 1089, 1766, 5981, 4194, 3447, 734, 8621, 8976, 1890, 4600, 1234, 5053, 2363, 1320, 1759, 2358, 734, 1770, 1650, 6336, 5393, 1906, 5971, 836, 2066, 2402, 4307, 2399, 2094, 3582, 2329, 14055, 2389, 1905, 5971, 5169, 3607, 5374, 2364, 4179, 5413, 769, 4927, 11281, 1804, 1539, 2085, 3751, 3607, 2987, 1067, 2984, 1190, 474, 1949, 11770, 5971, 834, 18498, 2045, 3251, 815, 2261, 2400, 1551, 2554, 1965, 838, 2388, 5044, 837, 4775, 1018, 12320, 4190, 1164, 2280, 469, 3706, 5354, 269, 5374, 9809, 1803, 3556, 5374, 816, 5080, 2069, 1219, 3322, 1430, 2461, 1099, 7456, 2384, 2200, 4583, 2563, 7457, 8360, 5971, 2045, 3425, 4012, 2277, 2286, 1189, 6368, 2264, 2079, 5019, 4776, 4776, 1936, 1441, 2767, 2143, 3978, 7218, 4576, 5969, 4777, 1099, 3072, 414, 2072, 2207, 2340, 5772, 4470, 2400, 3045, 4902, 2373, 835, 5374, 5971, 5395, 1544, 776, 1422, 6747, 1800, 3584, 4550, 7642, 5374, 1552, 5794, 2389, 5176, 4187, 3589, 3715, 4941, 1188, 2092, 4201, 989, 838, 3698, 956, 14047]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import lxml.html\n",
    "\n",
    "def parse_name_node(node):\n",
    "    return node.text\n",
    "\n",
    "def parse_price_node(node):\n",
    "    s = node.text\n",
    "    x = s[1:].replace(',', '')\n",
    "    return int( x )\n",
    "\n",
    "def parse_page_count_node(node):\n",
    "    s = node.text\n",
    "    if 'ページ' in s:\n",
    "        x = s.split(':')[1].split(',')[0]\n",
    "    else:\n",
    "        x = -1  # assign a value of -1 if \"ページ\" is not in the text field\n",
    "    return int( x )\n",
    "\n",
    "\n",
    "def parse_page(fnameHTML):\n",
    "    tree        = lxml.html.parse(fnameHTML)\n",
    "    body        = tree.find('body') \n",
    "    box         = body.find_class('itemCatBox')[0]\n",
    "    name_nodes  = box.find_class('name')\n",
    "    page_nodes  = box.find_class('itemCatsetsumei')\n",
    "    price_nodes = box.find_class('itemCatPrice')\n",
    "\n",
    "    # parse the entries:\n",
    "    title       = [parse_name_node( node )  for node in name_nodes]\n",
    "    pages       = [parse_page_count_node( node )  for node in page_nodes]\n",
    "    price       = [parse_price_node( node)  for node in price_nodes]\n",
    "    \n",
    "    return title, pages, price\n",
    "\n",
    "\n",
    "# specify data directory:\n",
    "dir0        = os.path.abspath('')              # directory in which this notebook is saved\n",
    "dirLesson   = os.path.dirname( dir0 )          # Lesson directory\n",
    "dirData     = os.path.join(dirLesson, 'Data')  # Data directory\n",
    "\n",
    "# parse all HTML pages:\n",
    "title  = []\n",
    "pages  = []\n",
    "price  = []\n",
    "\n",
    "for i in range(5):\n",
    "    fnameHTML = os.path.join(dirData, f'page{i+1}.html')\n",
    "    s,n,x     = parse_page(fnameHTML)\n",
    "    title    += s\n",
    "    pages    += n\n",
    "    price    += x\n",
    "\n",
    "print( len(title) )\n",
    "print( len(pages) )\n",
    "print( len(price) )\n",
    "print()\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "We now have book titles, page counts and prices saved in three separate lists, each of which has 200 elements.\n",
    "\n",
    "Let's ave these parsed data in a CSV file, so that our analysis code can focus on the data-of-interest in that CSV file. One way to do this is using the [csv](https://docs.python.org/3/library/csv.html) module (Japanese documentation [here](https://docs.python.org/ja/3/library/csv.html)).\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "fnameCSV = os.path.join( dir0, 'parsed_data.csv' )\n",
    "header   = ['Title', 'Pages', 'Price']  # column labels\n",
    "with open(fnameCSV, 'w') as f:          # open the CSV file in write mode\n",
    "    writer = csv.writer(f)              # create a writer object\n",
    "    writer.writerow( header )           # write column labels\n",
    "    for s,n,x in zip(title, pages, price):   # cycle through all entries\n",
    "        writer.writerow( [s, n, x] )    # write the current row to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "After executing this code, you will find a file called **parsed_data.csv** that has been saved to the directory in which this notebook is saved. Note that this file has three columns of data, corresponding to: title, pages, and price, respectively, and that these fields have been filled for all 200 books.\n",
    "\n",
    "Note especially:\n",
    "* The saved CSV file has a size of approximately **20 KB**.\n",
    "* Each of the original HTML data files have a size of approximately **240 KB**, for a total of about **1.2 MB**.\n",
    "* We have therefore greatly compressed the original data, by a factor of approximately 50.\n",
    "* This means that our analysis code --- which will use only the parsing results in the CSV file ---  will be able to execute much more efficiently.\n",
    "\n",
    "While use of the [csv](https://docs.python.org/3/library/csv.html) module is fine, it is usually more convenient to use [pandas](https://pandas.pydata.org). Using pandas, the csv file can be written using more compact, easier-to-read code:\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df       = pd.DataFrame( dict(Title=title, Pages=pages, Price=price) )\n",
    "df.to_csv(fnameCSV, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Like above, this code will write a CSV file that contains all data for all 200 books.\n",
    "\n",
    "Note that the command: `dict(Title=title, Pages=pages, Price=price)` creates a dictionary with keys: `Title`, `Pages` and `Price`, and that the `to_csv` method uses these keys as the column labels in the CSV file.\n",
    "\n",
    "Note also that the `index=False` keyword argument prevents the `to_csv` method from writing a column of row numbers. By default, `to_csv` will create a CSV file whose first column contains integers that indicate the row number.\n",
    "\n",
    "After writing the data, the contents of the CSV file can easily be re-read as follows:\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1075\n",
      "1       1790\n",
      "2       2379\n",
      "3       2364\n",
      "4        960\n",
      "       ...  \n",
      "195      989\n",
      "196      838\n",
      "197     3698\n",
      "198      956\n",
      "199    14047\n",
      "Name: Price, Length: 200, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df       = pd.read_csv(fnameCSV)\n",
    "title    = df['Title']\n",
    "page     = df['Pages']\n",
    "price    = df['Price']\n",
    "\n",
    "print( price )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Note that we can easily convert pandas objects to lists or NumPy arrays:\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1075, 1790, 2379, 2364, 960, 1219, 8491, 3205, 4729, 3033, 2352, 1581, 1801, 5374, 4325, 4526, 7192, 14542, 960, 834, 5388, 2385, 5136, 5408, 5374, 1076, 11060, 5900, 2567, 5152, 5374, 5374, 2153, 4531, 836, 4182, 1089, 1766, 5981, 4194, 3447, 734, 8621, 8976, 1890, 4600, 1234, 5053, 2363, 1320, 1759, 2358, 734, 1770, 1650, 6336, 5393, 1906, 5971, 836, 2066, 2402, 4307, 2399, 2094, 3582, 2329, 14055, 2389, 1905, 5971, 5169, 3607, 5374, 2364, 4179, 5413, 769, 4927, 11281, 1804, 1539, 2085, 3751, 3607, 2987, 1067, 2984, 1190, 474, 1949, 11770, 5971, 834, 18498, 2045, 3251, 815, 2261, 2400, 1551, 2554, 1965, 838, 2388, 5044, 837, 4775, 1018, 12320, 4190, 1164, 2280, 469, 3706, 5354, 269, 5374, 9809, 1803, 3556, 5374, 816, 5080, 2069, 1219, 3322, 1430, 2461, 1099, 7456, 2384, 2200, 4583, 2563, 7457, 8360, 5971, 2045, 3425, 4012, 2277, 2286, 1189, 6368, 2264, 2079, 5019, 4776, 4776, 1936, 1441, 2767, 2143, 3978, 7218, 4576, 5969, 4777, 1099, 3072, 414, 2072, 2207, 2340, 5772, 4470, 2400, 3045, 4902, 2373, 835, 5374, 5971, 5395, 1544, 776, 1422, 6747, 1800, 3584, 4550, 7642, 5374, 1552, 5794, 2389, 5176, 4187, 3589, 3715, 4941, 1188, 2092, 4201, 989, 838, 3698, 956, 14047]\n",
      "\n",
      "[ 1075  1790  2379  2364   960  1219  8491  3205  4729  3033  2352  1581\n",
      "  1801  5374  4325  4526  7192 14542   960   834  5388  2385  5136  5408\n",
      "  5374  1076 11060  5900  2567  5152  5374  5374  2153  4531   836  4182\n",
      "  1089  1766  5981  4194  3447   734  8621  8976  1890  4600  1234  5053\n",
      "  2363  1320  1759  2358   734  1770  1650  6336  5393  1906  5971   836\n",
      "  2066  2402  4307  2399  2094  3582  2329 14055  2389  1905  5971  5169\n",
      "  3607  5374  2364  4179  5413   769  4927 11281  1804  1539  2085  3751\n",
      "  3607  2987  1067  2984  1190   474  1949 11770  5971   834 18498  2045\n",
      "  3251   815  2261  2400  1551  2554  1965   838  2388  5044   837  4775\n",
      "  1018 12320  4190  1164  2280   469  3706  5354   269  5374  9809  1803\n",
      "  3556  5374   816  5080  2069  1219  3322  1430  2461  1099  7456  2384\n",
      "  2200  4583  2563  7457  8360  5971  2045  3425  4012  2277  2286  1189\n",
      "  6368  2264  2079  5019  4776  4776  1936  1441  2767  2143  3978  7218\n",
      "  4576  5969  4777  1099  3072   414  2072  2207  2340  5772  4470  2400\n",
      "  3045  4902  2373   835  5374  5971  5395  1544   776  1422  6747  1800\n",
      "  3584  4550  7642  5374  1552  5794  2389  5176  4187  3589  3715  4941\n",
      "  1188  2092  4201   989   838  3698   956 14047]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = list( price )\n",
    "b = np.array( price )\n",
    "\n",
    "print( a )\n",
    "print()\n",
    "print( b )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Great!  For use in the final section of this lesson, let's assemble all of our **parsing** code, including CSV data file writing.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Complete parsing code.\n",
    "'''\n",
    "\n",
    "import os\n",
    "import lxml.html\n",
    "import pandas\n",
    "\n",
    "def parse_name_node(node):\n",
    "    return node.text\n",
    "\n",
    "def parse_price_node(node):\n",
    "    s = node.text\n",
    "    x = s[1:].replace(',', '')\n",
    "    return int( x )\n",
    "\n",
    "def parse_page_count_node(node):\n",
    "    s = node.text\n",
    "    if 'ページ' in s:\n",
    "        x = s.split(':')[1].split(',')[0]\n",
    "    else:\n",
    "        x = -1  # assign a value of -1 if \"ページ\" is not in the text field\n",
    "    return int( x )\n",
    "\n",
    "\n",
    "def parse_page(fnameHTML):\n",
    "    tree        = lxml.html.parse(fnameHTML)\n",
    "    body        = tree.find('body') \n",
    "    box         = body.find_class('itemCatBox')[0]\n",
    "    name_nodes  = box.find_class('name')\n",
    "    page_nodes  = box.find_class('itemCatsetsumei')\n",
    "    price_nodes = box.find_class('itemCatPrice')\n",
    "\n",
    "    # parse the entries:\n",
    "    title       = [parse_name_node( node )  for node in name_nodes]\n",
    "    pages       = [parse_page_count_node( node )  for node in page_nodes]\n",
    "    price       = [parse_price_node( node)  for node in price_nodes]\n",
    "    \n",
    "    return title, pages, price\n",
    "\n",
    "\n",
    "\n",
    "# specify data directory:\n",
    "dir0        = os.path.abspath('')              # directory in which this notebook is saved\n",
    "dirLesson   = os.path.dirname( dir0 )          # Lesson directory\n",
    "dirData     = os.path.join(dirLesson, 'Data')  # Data directory\n",
    "\n",
    "\n",
    "# parse all HTML pages:\n",
    "title  = []\n",
    "pages  = []\n",
    "price  = []\n",
    "for i in range(5):\n",
    "    fnameHTML = os.path.join(dirData, f'page{i+1}.html')\n",
    "    s,n,x     = parse_page(fnameHTML)\n",
    "    title    += s\n",
    "    pages    += n\n",
    "    price    += x\n",
    "\n",
    "\n",
    "# write parsed results:\n",
    "df       = pd.DataFrame( dict(Title=title, Pages=pages, Price=price) )\n",
    "fnameCSV = os.path.join( dir0, 'parsed_data.csv' )\n",
    "df.to_csv(fnameCSV, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "OK, now that we've completed our **parsing** code, let's next move on to **analysis**, which is discussed in the next notebook.\n",
    "\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
