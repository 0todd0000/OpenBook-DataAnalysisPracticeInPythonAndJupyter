{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#54B1FF\">Machine Learning V:</span> &nbsp; <span style=\"color:#1B3EA9\"><b>Dimensionality Reduction (Overview)</b></span>\n",
    "\n",
    "<br>\n",
    "\n",
    "An important first step in many machine learning problems is [dimensionality reduction](https://en.wikipedia.org/wiki/Dimensionality_reduction). Dimensionality reduction refers to a processes that transforms a large number of features (i.e., variables) into a smaller number of new variables. Dimensionality reduction is therefore useful mainly when there are many features (usually five or more, but sometimes also useful even if there are just two features).\n",
    "\n",
    "The new variables are often abstract combinations of the original features, and cannot readily be interpreted in the context of the original features.  These new variables nevertheless usually represent the statistically most important variance in the dataset.\n",
    "\n",
    "The easiest way to understand these and other dimensionality reduction concepts is by example. This lecture aims to use a number of examples to explain key concepts regarding dimensionality reduction.\n",
    "\n",
    "**Notes**:\n",
    "\n",
    "* The most common dimensionality reduction algorithm, by far, is [principal components analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis)\n",
    "* There are many other kinds of dimensionality reduction algorithms, including for example [independent components analysis (ICA)](https://en.wikipedia.org/wiki/Independent_component_analysis).\n",
    "* Nevertheless, it is sufficient to focus on just one algorithm to understand the main concepts underlying dimensionality reduction.\n",
    "* This chapter therefore considers only PCA, with the understanding that most concepts are relevant to other dimensionality reduction algorithms.\n",
    "* For details of a wider variety of possibilities, refer to [sklearn's dimensionality reduciton documentation](https://scikit-learn.org/stable/modules/decomposition.html).\n",
    "\n",
    "\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
